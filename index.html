<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Gang Zhou - Academic Pages</title>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
    />
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      }

      body {
        background-color: #f5f7fa;
        color: #333;
        line-height: 1.6;
        display: flex;
        justify-content: center;
        min-height: 100vh;
        padding: 20px;
      }

      .container-wrapper {
        max-width: 1200px;
        width: 100%;
      }

      .container {
        display: flex;
        background-color: white;
        border-radius: 15px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.08);
        overflow: hidden;
        position: relative;
      }

      .sidebar {
        width: 300px;
        background-color: #f9f9f9;
        border-right: 1px solid #eaeaea;
        padding: 40px 25px;
        display: flex;
        flex-direction: column;
        align-items: center;
      }

      .real-avatar {
        width: 150px;
        height: 150px;
        border-radius: 50%;
        margin-bottom: 20px;
        object-fit: cover;
        border: 3px solid #fff;
        box-shadow: 0 8px 15px rgba(0, 0, 0, 0.1);
        max-width: 100%;
        display: block;
        box-sizing: content-box;
      }

      .profile-name {
        font-size: 24px;
        font-weight: 600;
        margin-bottom: 10px;
        color: #2c3e50;
        text-align: center;
      }

      .bio {
        text-align: center;
        font-size: 14px;
        color: #7f8c8d;
        margin-bottom: 30px;
        padding: 0 10px;
        max-width: 100%;
      }

      .links {
        width: 100%;
      }

      .link-item {
        display: flex;
        align-items: center;
        padding: 12px 15px;
        margin-bottom: 8px;
        border-radius: 6px;
        transition: all 0.3s ease;
        color: #3498db;
        text-decoration: none;
        background-color: white;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
      }

      .link-item:hover {
        background-color: #eef7ff;
        transform: translateX(5px);
        color: #2980b9;
        box-shadow: 0 3px 6px rgba(0, 0, 0, 0.08);
      }

      .link-item i {
        font-size: 20px;
        margin-right: 15px;
        width: 24px;
        text-align: center;
      }

      .content {
        flex: 1;
        padding: 40px;
        max-width: 900px;
      }

      .page-title {
        font-size: 28px;
        margin-bottom: 25px;
        color: #2c3e50;
        font-weight: 700;
        position: relative;
        padding-bottom: 10px;
      }

      .page-title::after {
        content: "";
        position: absolute;
        bottom: 0;
        left: 0;
        width: 80px;
        height: 4px;
        background: linear-gradient(to right, #3498db, #8e44ad);
        border-radius: 2px;
      }

      .description {
        margin-bottom: 20px;
        font-size: 16px;
        color: #34495e;
        line-height: 1.8;
      }

      .highlight {
        background-color: #f8f9fa;
        border-left: 4px solid #3498db;
        padding: 25px;
        margin: 30px 0;
        border-radius: 0 8px 8px 0;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.03);
      }

      .section-title {
        font-size: 24px;
        margin: 40px 0 20px;
        color: #2c3e50;
        font-weight: 600;
        position: relative;
        padding-left: 15px;
      }

      .section-title::before {
        content: "";
        position: absolute;
        left: 0;
        top: 50%;
        transform: translateY(-50%);
        height: 24px;
        width: 4px;
        background: #3498db;
        border-radius: 2px;
      }

      .concept {
        padding: 25px;
        background-color: #f5f7fa;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
        margin-top: 20px;
      }

      .concept p {
        margin-bottom: 15px;
      }

      .link-orcid {
        color: #a6ce39;
      }

      .link-pubmed {
        color: #0078af;
      }

      .footer {
        text-align: center;
        margin-top: 40px;
        color: #7f8c8d;
        font-size: 14px;
        padding: 20px;
      }

      @media (max-width: 992px) {
        .container {
          flex-direction: column;
        }

        .sidebar {
          width: 100%;
          border-right: none;
          border-bottom: 1px solid #eaeaea;
        }

        .content {
          padding: 30px 20px;
        }

        .container-wrapper {
          padding: 10px;
        }
      }

      @media (max-width: 480px) {
        .real-avatar {
          width: 120px;
          height: 120px;
        }
      }

      /* 论文展示样式 */
      .publication-item {
        margin-bottom: 40px;
        padding: 20px;
        background-color: white;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
      }

      .pub-top-row {
        display: flex;
        gap: 20px;
        margin-bottom: 15px;
      }

      .pub-image {
        flex: 0 0 180px;
        display: flex;
        justify-content: center;
        align-items: center;
      }

      .pub-image img {
        max-width: 100%;
        height: auto;
        border-radius: 8px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
      }

      .pub-info {
        flex: 1;
      }

      .pub-title {
        font-size: 20px;
        font-weight: 600;
        margin-bottom: 10px;
        color: #2c3e50;
      }

      .pub-title a {
        text-decoration: none;
        color: inherit;
        transition: color 0.3s;
      }

      .pub-title a:hover {
        color: #3498db;
        text-decoration: underline;
      }

      .pub-authors {
        font-size: 16px;
        color: #34495e;
        margin-bottom: 8px;
      }

      .pub-authors strong {
        font-weight: 600;
        color: #2980b9;
      }

      .pub-venue {
        font-style: italic;
        margin-bottom: 12px;
        color: #7f8c8d;
      }

      .pub-links {
        display: flex;
        gap: 15px;
      }

      .pub-links a {
        display: inline-block;
        padding: 6px 12px;
        background-color: #f0f7ff;
        color: #3498db;
        text-decoration: none;
        border-radius: 4px;
        font-size: 14px;
        transition: all 0.3s;
        border: 1px solid #d4e5f7;
      }

      .pub-links a:hover {
        background-color: #3498db;
        color: white;
        border-color: #3498db;
      }

      .pub-abstract {
        font-size: 15px;
        line-height: 1.6;
        color: #34495e;
      }

      .pub-abstract .highlight {
        background: linear-gradient(
          120deg,
          rgba(41, 128, 185, 0.1),
          transparent
        );
        padding: 0 5px;
        font-weight: 600;
        border-radius: 3px;
      }

      @media (max-width: 768px) {
        .pub-top-row {
          flex-direction: column;
        }

        .pub-image {
          flex: 0 0 auto;
          margin: 0 auto 15px;
        }

        .pub-title {
          text-align: center;
        }

        .pub-links {
          justify-content: center;
        }
      }
    </style>
  </head>
  <body>
    <div class="container-wrapper">
      <div class="container">
        <!-- 左侧侧边栏 -->
        <aside class="sidebar">
          <img src="images/GangZhou.jpg" class="real-avatar" alt="Gang Zhou" />
          <h1 class="profile-name">Gang Zhou(周刚)</h1>
          <p class="bio">PhD Candidate</p>
          <div class="links">
            <a href="https://www.bupt.edu.cn//" class="link-item">
              <i class="fas fa-university"></i>
              <span>Beijing University of Posts and Telecommunications</span>
            </a>
            <a href="mailto:g.zhou@seu.edu.cn" class="link-item">
              <i class="fas fa-envelope"></i>
              <span>zg_pem@163.com</span>
            </a>
            <a
              href="https://orcid.org/0009-0002-1180-6942"
              class="link-item link-orcid"
            >
              <i class="fab fa-orcid"></i>
              <span>ORCID</span>
            </a>
            <a href="https://github.com/zhougang2020" class="link-item">
              <i class="fab fa-github"></i>
              <span>GitHub</span>
            </a>
          </div>
        </aside>

        <!-- 右侧内容区 - 包含所有三篇论文 -->
        <main class="content">
          <h1 class="page-title">About me</h1>
          <p class="description">
            My name is Gang Zhou, and I am currently pursuing a Ph.D. at the
            School of Artificial Intelligence, Beijing University of Posts and
            Telecommunications, with an expected graduation year of 2027.
          </p>

          <h2 class="section-title">Research</h2>
          My research interests include
          <strong>trustworthy multimodal retrieval</strong> and
          <strong>vision-language models</strong>.
          <p>* denotes equal contributions.</p>
          <!-- 论文条目1：Reason-RFT -->
          <div class="publication-item">
            <div class="pub-top-row">
              <div class="pub-image">
                <img src="images/FACH.png" alt="FACH" />
              </div>
              <div class="pub-info">
                <div class="pub-title">
                  <a href="papers/TSMC.pdf">
                    Frequency Domain Adversarial Attacks on Deep Cross-Modal
                    Hashing
                  </a>
                </div>
                <div class="pub-authors">
                  <strong>Gang Zhou</strong>, Shibiao Xu, Xiaolong Zheng,
                  Guiyang Luo,, and Fei-Yue Wang
                </div>
                <div class="pub-venue">
                  <em>Submitted to IEEE TSMC</em>, 2025
                </div>
                <div class="pub-links">
                  <a href="papers/TSMC.pdf">Paper</a>
                </div>
              </div>
            </div>
            <div class="pub-abstract">
              <p>
                We propose <span class="highlight">FACH</span>, a frequency
                domain adversarial attack method for deep cross-modal hashing
                retrieval systems, which combines low-frequency masking and
                multi-teacher gradient fusion to reveal the vulnerabilities of
                deep hashing models in the frequency domain. Experimental
                results show that FACH significantly outperforms existing
                transfer attack methods, enhancing the transferability and
                effectiveness of adversarial attacks.
              </p>
            </div>
          </div>

          <!-- 论文条目2：SAAT -->
          <div class="publication-item">
            <div class="pub-top-row">
              <div class="pub-image">
                <img src="images/SAAT.jpg" alt="SAAT" />
              </div>
              <div class="pub-info">
                <div class="pub-title">
                  <a href="papers/SAAT.pdf">
                    Deep Supervised Adversarial Robust Hashing for Retrieval
                  </a>
                </div>
                <div class="pub-authors">
                  Xingwei Zhang, <strong>Gang Zhou*</strong>, Xiaolong Zheng,
                  Wenji Mao, Liang Wang, and Daniel Dajun Zeng
                </div>
                <div class="pub-venue">
                  <em
                    >Submitted to IEEE TPAMI (first-round revision in
                    progress)</em
                  >, 2024
                </div>
                <div class="pub-links">
                  <a href="papers/SAAT.pdf">Paper</a>
                </div>
              </div>
            </div>
            <div class="pub-abstract">
              <p>
                We propose <span class="highlight">SAAT</span>, an end-to-end
                adversarial training framework that enhances the robustness of
                deep hashing models for retrieval tasks. By integrating
                adversarial perturbations with hash code learning and similarity
                matrices, SAAT outperforms existing methods in cross-modal and
                image retrieval tasks while maintaining robustness against
                various attacks.
              </p>
            </div>
          </div>

          <!-- 论文条目3：BACH - 已修复位置 -->
          <div class="publication-item">
            <div class="pub-top-row">
              <div class="pub-image">
                <img src="images/BACH.png" alt="BACH" />
              </div>
              <div class="pub-info">
                <div class="pub-title">
                  <a
                    href="https://link.springer.com/chapter/10.1007/978-3-031-30675-4_32"
                  >
                    BACH: Black-Box Attacking on Deep Cross-Modal Hamming
                    Retrieval Models
                  </a>
                </div>
                <div class="pub-authors">
                  Jie Zhang, <strong>Gang Zhou*</strong>, Qianyu Guo, Zhiyong
                  Feng, and Xiaohong Li
                </div>
                <div class="pub-venue"><em>DASFAA (CCF-B)</em>, 2023</div>
                <div class="pub-links">
                  <a href="papers/BACH.pdf">Paper</a>
                  <a
                    href="https://link.springer.com/chapter/10.1007/978-3-031-30675-4_32"
                    >Homepage</a
                  >
                </div>
              </div>
            </div>
            <div class="pub-abstract">
              <p>
                We propose <span class="highlight">BACH</span>, an adversarial
                attack method for deep cross-modal hashing retrieval (DCMHR)
                models in black-box settings. By incorporating Random
                Gradient-Free Estimation (RGF) into deep hashing attacks, BACH
                generates effective adversarial samples without prior knowledge
                of the target model. Experiments show that BACH achieves attack
                success rates comparable to white-box attacks.
              </p>
            </div>
          </div>

          <!-- 论文条目4：STCH - 已修复位置 -->
          <div class="publication-item">
            <div class="pub-top-row">
              <div class="pub-image">
                <img src="images/STCH.png" alt="STCH" />
              </div>
              <div class="pub-info">
                <div class="pub-title">
                  <a href="https://ieeexplore.ieee.org/document/9892301">
                    Self-Training Based Semi-Supervised and Semi-Paired Hashing
                    Cross-Modal Retrieval
                  </a>
                </div>
                <div class="pub-authors">
                  Rongrong Jing, Hu Tian, Xingwei Zhang,
                  <strong>Gang Zhou</strong>, Xiaolong Zheng, Dajun Zeng
                </div>
                <div class="pub-venue"><em>IJCNN (CCF-C)</em>, 2022</div>
                <div class="pub-links">
                  <a href="papers/STCH.pdf">Paper</a>
                  <a href="https://ieeexplore.ieee.org/document/9892301"
                    >Homepage</a
                  >
                </div>
              </div>
            </div>
            <div class="pub-abstract">
              <p>
                We propose <span class="highlight">STCH</span>, a
                self-training-based cross-modal hashing framework designed to
                address semi-supervised and semi-paired problems. The framework
                leverages graph neural networks to capture inter-modality
                similarities and generate pseudo-labels, which are then refined
                using a heuristic filter to enhance label consistency. Through
                an alternating learning strategy for self-training, STCH
                outperforms existing methods in cross-modal hashing retrieval
                tasks.
              </p>
            </div>
          </div>

          <!-- 论文条目5：FEM - 已修复位置 -->
          <div class="publication-item">
            <div class="pub-top-row">
              <div class="pub-info">
                <div class="pub-title">
                  <a
                    href="https://link.springer.com/article/10.1007/s42524-022-0241-1"
                  >
                    Platform governance in the era of AI and the digital economy
                  </a>
                </div>
                <div class="pub-authors">
                  Xiaolong Zheng, <strong>Gang Zhou*</strong>, Daniel Dajun Zeng
                </div>
                <div class="pub-venue">
                  <em>Frontiers of Engineering Management</em>, 2023
                </div>
                <div class="pub-links">
                  <a href="papers/FEM.pdf">Paper</a>
                  <a
                    href="https://link.springer.com/article/10.1007/s42524-022-0241-1"
                    >Homepage</a
                  >
                </div>
              </div>
            </div>
          </div>

          <!-- 论文条目5：FEM - 已修复位置 -->
          <div class="publication-item">
            <div class="pub-top-row">
              <div class="pub-info">
                <div class="pub-title">
                  <a
                    href="https://ieeexplore.ieee.org/abstract/document/9540168"
                  >
                    Analyzing the Hidden Causal Interactions in Large-Scale
                    Social Networks: A Case Study on GameStop
                  </a>
                </div>
                <div class="pub-authors">
                  <strong>Gang Zhou</strong>, Rongrong Jing, Xiaolong Zheng,
                  Xingwei Zhang, Hu Tian, Daniel Zeng
                </div>
                <div class="pub-venue"><em>DTPI</em>, 2021</div>
                <div class="pub-links">
                  <a href="papers/DTPI.pdf">Paper</a>
                  <a
                    href="https://ieeexplore.ieee.org/abstract/document/9540168"
                    >Homepage</a
                  >
                </div>
              </div>
            </div>
          </div>
        </main>
      </div>

      <div class="footer">
        © 2025 Gang Zhou | 周刚 | Beijing University of Posts and
        Telecommunications
      </div>
    </div>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        const avatar = document.querySelector(".real-avatar");
        avatar.onerror = function () {
          this.src =
            "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNTAiIGhlaWdodD0iMTUwIiB2aWV3Qm94PSIwIDAgMjQgMjQiIGZpbGw9IiM2YTliZDgiPjxwYXRoIGQ9Ik0xMiwxMkMxNSw5IDIwLDkuOCAyMCwxMiBDMjAsMTUgMTUsMTUgMTIsMTIiLz48cGF0aCBkPSJNMTIsMTJDNywxNSA0LDE1IDQsMTIgQzQsOSA5LDkgMTIsMTIiLz48cGF0aCBkPSJNMTIsMi41IEE0LjUsNC41IDAgMCAwIDEyLDExLjUgQTQuNSw0LjUgMCAwIDAgMTIsMi41IFoiLz48L3N2Zz4=";
          this.alt = "头像加载失败";
        };
      });
    </script>
  </body>
</html>
